{
 "cells": [
  {
   "cell_type": "code",
   "id": "d8287d1fd50cc43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:29.565540Z",
     "start_time": "2025-05-09T22:04:28.842754Z"
    }
   },
   "source": [
    "#  PredictionBot\n",
    "#  Copyright (C) 2025 CatraMyBeloved\n",
    "#\n",
    "#  This program is free software: you can redistribute it and/or modify\n",
    "#  it under the terms of the GNU General Public License as published by\n",
    "#  the Free Software Foundation, either version 3 of the License, or\n",
    "#  (at your option) any later version.\n",
    "#\n",
    "#  This program is distributed in the hope that it will be useful,\n",
    "#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#  GNU General Public License for more details.\n",
    "#\n",
    "#  You should have received a copy of the GNU General Public License\n",
    "#  along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:29.595121Z",
     "start_time": "2025-05-09T22:04:29.586133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "table_names = [\"teams\", \"bans\", \"hero_composition\", \"heroes\",\n",
    "               \"maps\", \"match_maps\", \"matches\", \"rounds\"]\n",
    "\n",
    "def load_data_from_sqlite(table_name: str,db_path: str = \"../../data/owcs.db\") \\\n",
    "        -> (\n",
    "        pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Load data from a SQLite database into a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        db_path (str): Path to the SQLite database file.\n",
    "        table_name (str): Name of the table to load.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Load data from the specified table into a DataFrame\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_all_tables(db_path: str = \"../../data/owcs.db\") -> dict:\n",
    "    \"\"\"\n",
    "    Load all tables from the SQLite database into a dictionary of DataFrames.\n",
    "\n",
    "    Args:\n",
    "        db_path (str): Path to the SQLite database file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing DataFrames for each table.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for table_name in table_names:\n",
    "        data[table_name] = load_data_from_sqlite(table_name, db_path)\n",
    "    return data"
   ],
   "id": "1646236110246a15",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:29.654035Z",
     "start_time": "2025-05-09T22:04:29.601195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_all_tables()\n",
    "\n",
    "hero_composition = data[\"hero_composition\"]\n",
    "rounds = data[\"rounds\"]\n",
    "match_maps = data[\"match_maps\"]\n",
    "matches = data[\"matches\"]\n",
    "teams = data[\"teams\"]\n",
    "heroes = data[\"heroes\"]\n",
    "maps = data[\"maps\"]\n",
    "bans = data[\"bans\"]\n",
    "\n",
    "def determine_iswin(row: pd.Series) -> int:\n",
    "    if row[\"team\"] == row[\"map_win_team_id\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def join_all_tables() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Join all tables in the database to create a comprehensive DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the joined data.\n",
    "    \"\"\"\n",
    "    # Join the tables using the appropriate keys\n",
    "    df = pd.merge(hero_composition, heroes, on = \"hero_id\")\n",
    "    df = pd.merge(df, rounds, on=\"round_id\")\n",
    "    df = pd.merge(df, match_maps, on=\"match_map_id\")\n",
    "    df = pd.merge(df, matches, on=\"match_id\")\n",
    "    df = pd.merge(df, teams, left_on=\"team\", right_on=\"team_id\")\n",
    "    df = pd.merge(df, maps, on=\"map_id\")\n",
    "    df[\"is_win\"]  = df.apply(determine_iswin, axis=1)\n",
    "\n",
    "    return df"
   ],
   "id": "d66b5af998ba92b9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:29.905878Z",
     "start_time": "2025-05-09T22:04:29.899072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def played_hero_transformation(group_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Transform the played hero data for each team in a match.\n",
    "\n",
    "    Args:\n",
    "        group_df (pd.DataFrame): DataFrame containing the played hero data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame with played hero data.\n",
    "    \"\"\"\n",
    "    tank_played = group_df[group_df.role == \"tank\"]\n",
    "    dps_played = group_df[group_df.role == \"dps\"].head(2)\n",
    "    support_played = group_df[group_df.role == \"sup\"].head(2)\n",
    "    map_name = group_df[\"map_name\"].values[0]\n",
    "    is_win = group_df[\"is_win\"].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    transformed_dict = {\n",
    "        \"map_name\": map_name,\n",
    "        \"is_win\": is_win,\n",
    "        \"tank_hero\": tank_played[\"hero_name\"].values[0],\n",
    "        \"dps_heroes\": list(dps_played[\"hero_name\"].values.tolist()),\n",
    "        \"support_heroes\": list(support_played[\"hero_name\"].values.tolist())\n",
    "    }\n",
    "\n",
    "\n",
    "    return pd.Series(transformed_dict)"
   ],
   "id": "d1af8275c80a33d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:30.013318Z",
     "start_time": "2025-05-09T22:04:30.006385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def create_composition_table() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a DataFrame containing the hero composition for each map.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the hero composition.\n",
    "    \"\"\"\n",
    "    df = join_all_tables()\n",
    "\n",
    "    # group table by matchmap_id and round_id\n",
    "\n",
    "    all_columns = list(df.columns)\n",
    "\n",
    "    df = df.groupby([\"match_map_id\", \"round_id\", \"team_id\"])\n",
    "\n",
    "    transformed_series = df[all_columns].apply(played_hero_transformation)\n",
    "\n",
    "    transformed_df = transformed_series.reset_index()\n",
    "\n",
    "    transformed_df['team_index'] = transformed_df.groupby('round_id').cumcount()\n",
    "\n",
    "    return transformed_df"
   ],
   "id": "d65e60a042838f27",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:30.081428Z",
     "start_time": "2025-05-09T22:04:30.075312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_opponents(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_opponents = df.copy()\n",
    "\n",
    "    df_opponents = df_opponents[[\"round_id\", \"team_id\",\"team_index\", \"tank_hero\", \"dps_heroes\", \"support_heroes\"]]\n",
    "\n",
    "    self_merged_df = pd.merge(df, df_opponents, on=\"round_id\", suffixes=(\"\", \"_opp\"))\n",
    "\n",
    "    self_merged_df = self_merged_df[self_merged_df[\"team_index\"] != self_merged_df[\"team_index_opp\"]]\n",
    "\n",
    "    return self_merged_df"
   ],
   "id": "cae51c5d04b0582d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:30.096830Z",
     "start_time": "2025-05-09T22:04:30.090525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# group by round_id and sample one row per round\n",
    "def sample_one_per_round(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sample one row per round from the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with one row per round.\n",
    "    \"\"\"\n",
    "    all_columns = list(df.columns)\n",
    "    sampled_df = df.groupby(\"round_id\")[all_columns].apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "    return sampled_df\n"
   ],
   "id": "4688f232b02b219d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:30.127595Z",
     "start_time": "2025-05-09T22:04:30.120956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_bans(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add ban information to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with ban information added.\n",
    "    \"\"\"\n",
    "    bans = data[\"bans\"]\n",
    "    joined_team1 = pd.merge(df, bans, on=[\"match_map_id\", \"team_id\"], how=\"left\")\n",
    "    joined_team1.rename(columns={\"hero_id\": \"ban_hero\"}, inplace=True)\n",
    "    joined_team2 = pd.merge(joined_team1, bans, left_on=[\"match_map_id\", \"team_id_opp\"], right_on = [\"match_map_id\", \"team_id\"], how=\"left\", suffixes=(\"\", \"_opp_2\"))\n",
    "    joined_team2.rename(columns={\"hero_id\": \"ban_hero_opp\"}, inplace=True)\n",
    "\n",
    "    return joined_team2\n"
   ],
   "id": "79fb7d4108cba610",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:11:37.917370Z",
     "start_time": "2025-05-09T22:11:37.908459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the DataFrame by dropping unnecessary columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    columns_to_drop = [\"match_map_id\", \"round_id\", \"team_index\", \"team_index_opp\", \"first_bool\", \"first_bool_opp_2\", \"team_id_opp_2\"]\n",
    "    columns_to_int = [\"team_id\", \"team_id_opp\", \"ban_hero\", \"ban_hero_opp\"]\n",
    "    cleaned_df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # 2. Drop any rows where these columns are null\n",
    "    cleaned_df = cleaned_df.dropna(subset=columns_to_int)\n",
    "\n",
    "    # 3. Now safely cast to int\n",
    "    for col in columns_to_int:\n",
    "        cleaned_df[col] = cleaned_df[col].astype(int)\n",
    "    return cleaned_df"
   ],
   "id": "29587bb2981cea05",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:26:52.657030Z",
     "start_time": "2025-05-09T22:26:52.649974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_prediction_data(df, heroes_df, teams_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the data for prediction by joining with heroes table\n",
    "    and selecting only the necessary columns.\n",
    "    \"\"\"\n",
    "    # Join ban_hero with heroes table\n",
    "    df_with_bans = df.copy()\n",
    "    df_with_bans = df_with_bans.merge(\n",
    "        heroes_df[['hero_id', 'hero_name']],\n",
    "        left_on='ban_hero',\n",
    "        right_on='hero_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_ban')\n",
    "    ).rename(columns={'hero_name': 'banned_hero'})\n",
    "\n",
    "    # Join ban_hero_opp with heroes table\n",
    "    df_with_bans = df_with_bans.merge(\n",
    "        heroes_df[['hero_id', 'hero_name']],\n",
    "        left_on='ban_hero_opp',\n",
    "        right_on='hero_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_ban_opp')\n",
    "    ).rename(columns={'hero_name': 'banned_hero_opp'})\n",
    "\n",
    "    df_with_bans = df_with_bans.merge(\n",
    "        teams_df[['team_id', 'team_name']],\n",
    "        left_on='team_id',\n",
    "        right_on='team_id',\n",
    "        how='left',\n",
    "    ).rename(columns={'team_name': 'team_name_x'})\n",
    "\n",
    "    df_with_bans = df_with_bans.merge(\n",
    "        teams_df[['team_id', 'team_name']],\n",
    "        left_on='team_id_opp',\n",
    "        right_on='team_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_opp')\n",
    "    ).rename(columns={'team_name': 'team_name_opp'})\n",
    "\n",
    "    relevant_df = df_with_bans[[\n",
    "        \"team_name_x\",\n",
    "        \"team_name_opp\",\n",
    "        \"map_name\",\n",
    "        \"is_win\",\n",
    "        \"banned_hero\",\n",
    "        \"banned_hero_opp\"\n",
    "    ]].rename(columns = {\"team_name_x\" : \"team_name\"})\n",
    "\n",
    "    return relevant_df"
   ],
   "id": "3d7dfe9b86fe42c6",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:27:48.503842Z",
     "start_time": "2025-05-09T22:27:48.495154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ],
   "id": "ccbb21bd73a6acf3",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:24:27.307104Z",
     "start_time": "2025-05-09T22:24:22.916963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transformed_data = sample_one_per_round(add_opponents(create_composition_table()))\n",
    "transformed_data = add_bans(transformed_data)"
   ],
   "id": "ab6dab7b6f29bf81",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:26:55.010481Z",
     "start_time": "2025-05-09T22:26:54.985651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ml_data = clean_table(transformed_data)\n",
    "ml_data_prepared = prepare_prediction_data(ml_data, heroes, teams)"
   ],
   "id": "518c12423d08f08d",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:27:17.823597Z",
     "start_time": "2025-05-09T22:27:17.814538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = ml_data_prepared.drop(columns=[\"is_win\"])\n",
    "y = ml_data_prepared[\"is_win\"]"
   ],
   "id": "897d443164a4df1b",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:27:59.219656Z",
     "start_time": "2025-05-09T22:27:59.211305Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)",
   "id": "1a409386bdf57ee5",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:28:35.302990Z",
     "start_time": "2025-05-09T22:28:35.291368Z"
    }
   },
   "cell_type": "code",
   "source": "categorical_transformer = OneHotEncoder(handle_unknown='ignore')",
   "id": "a841bdfdd005c925",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:28:59.538788Z",
     "start_time": "2025-05-09T22:28:59.531304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, X.columns)\n",
    "    ])"
   ],
   "id": "72807d34fdebbb7e",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:30:03.895820Z",
     "start_time": "2025-05-09T22:30:03.891138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])"
   ],
   "id": "6bcdef619a657bc7",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:30:10.730734Z",
     "start_time": "2025-05-09T22:30:07.498899Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(X_train, y_train)",
   "id": "2f149f92c5415e89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  Index(['team_name', 'team_name_opp', 'map_name', 'banned_hero',\n",
       "       'banned_hero_opp'],\n",
       "      dtype='object'))])),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(n_estimators=1000, random_state=42))])"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  Index([&#x27;team_name&#x27;, &#x27;team_name_opp&#x27;, &#x27;map_name&#x27;, &#x27;banned_hero&#x27;,\n",
       "       &#x27;banned_hero_opp&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=1000, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  Index([&#x27;team_name&#x27;, &#x27;team_name_opp&#x27;, &#x27;map_name&#x27;, &#x27;banned_hero&#x27;,\n",
       "       &#x27;banned_hero_opp&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=1000, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 Index([&#x27;team_name&#x27;, &#x27;team_name_opp&#x27;, &#x27;map_name&#x27;, &#x27;banned_hero&#x27;,\n",
       "       &#x27;banned_hero_opp&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;team_name&#x27;, &#x27;team_name_opp&#x27;, &#x27;map_name&#x27;, &#x27;banned_hero&#x27;,\n",
       "       &#x27;banned_hero_opp&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=1000, random_state=42)</pre></div> </div></div></div></div></div></div>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:30:13.429637Z",
     "start_time": "2025-05-09T22:30:13.340857Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Accuracy: {model.score(X_test, y_test):.4f}\")",
   "id": "dfa48cb9e5ef5f05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8844\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:30:15.511657Z",
     "start_time": "2025-05-09T22:30:15.422231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "3937074d21ab5a12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       175\n",
      "           1       0.88      0.88      0.88       171\n",
      "\n",
      "    accuracy                           0.88       346\n",
      "   macro avg       0.88      0.88      0.88       346\n",
      "weighted avg       0.88      0.88      0.88       346\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[155  20]\n",
      " [ 20 151]]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:32:04.189445Z",
     "start_time": "2025-05-09T22:31:58.645128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a list of models to try\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=150, random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=150, random_state=42)\n",
    "}\n",
    "\n",
    "# Compare models with cross-validation\n",
    "results = {}\n",
    "for name, model_clf in models.items():\n",
    "    # Create a pipeline with this model\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model_clf)\n",
    "    ])\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    results[name] = {\n",
    "        'mean_score': cv_scores.mean(),\n",
    "        'std_score': cv_scores.std()\n",
    "    }\n",
    "    print(f\"{name}: Accuracy = {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")"
   ],
   "id": "b3358722410a2038",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy = 0.8958 (±0.0247)\n",
      "Logistic Regression: Accuracy = 0.7156 (±0.0122)\n",
      "XGBoost: Accuracy = 0.8415 (±0.0220)\n",
      "[LightGBM] [Info] Number of positive: 548, number of negative: 557\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 212\n",
      "[LightGBM] [Info] Number of data points in the train set: 1105, number of used features: 106\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495928 -> initscore=-0.016290\n",
      "[LightGBM] [Info] Start training from score -0.016290\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 548, number of negative: 557\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 1105, number of used features: 101\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495928 -> initscore=-0.016290\n",
      "[LightGBM] [Info] Start training from score -0.016290\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 548, number of negative: 558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 206\n",
      "[LightGBM] [Info] Number of data points in the train set: 1106, number of used features: 103\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495479 -> initscore=-0.018084\n",
      "[LightGBM] [Info] Start training from score -0.018084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 548, number of negative: 558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 204\n",
      "[LightGBM] [Info] Number of data points in the train set: 1106, number of used features: 102\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495479 -> initscore=-0.018084\n",
      "[LightGBM] [Info] Start training from score -0.018084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 548, number of negative: 558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 208\n",
      "[LightGBM] [Info] Number of data points in the train set: 1106, number of used features: 104\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495479 -> initscore=-0.018084\n",
      "[LightGBM] [Info] Start training from score -0.018084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM: Accuracy = 0.8545 (±0.0150)\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "selected models, random forest, extra trees, neural network",
   "id": "b25a12b57d329cd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:46:48.424601Z",
     "start_time": "2025-05-09T22:46:48.409644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import numpy as np\n",
    "\n",
    "# Random Forest hyperparameter grid\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': randint(100, 1000),  # Number of trees\n",
    "    'classifier__max_depth': [None, 10, 20, 30, 40, 50],  # Max tree depth\n",
    "    'classifier__min_samples_split': randint(2, 20),  # Min samples to split\n",
    "    'classifier__min_samples_leaf': randint(1, 10),  # Min samples at leaf\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],  # Features per split\n",
    "    'classifier__bootstrap': [True, False],  # Bootstrap samples\n",
    "    'classifier__class_weight': ['balanced', 'balanced_subsample', None]  # Class weighting\n",
    "}\n",
    "\n",
    "# Extra Trees hyperparameter grid\n",
    "et_param_grid = {\n",
    "    'classifier__n_estimators': randint(100, 1000),\n",
    "    'classifier__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'classifier__min_samples_split': randint(2, 20),\n",
    "    'classifier__min_samples_leaf': randint(1, 10),\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "    'classifier__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}\n",
    "\n",
    "# Neural Network hyperparameter grid\n",
    "nn_param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'classifier__activation': ['relu', 'tanh'],\n",
    "    'classifier__alpha': uniform(0.0001, 0.01),  # L2 regularization\n",
    "    'classifier__learning_rate_init': uniform(0.001, 0.1),\n",
    "    'classifier__batch_size': [32, 64, 128, 'auto'],\n",
    "    'classifier__solver': ['adam', 'sgd'],\n",
    "    'classifier__early_stopping': [True, False]\n",
    "}"
   ],
   "id": "4f0770b7e3f1ce91",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:46:56.006117Z",
     "start_time": "2025-05-09T22:46:55.995536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create pipelines\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "et_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ExtraTreesClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "nn_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', MLPClassifier(max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "# Store pipelines in a dictionary for easier handling\n",
    "pipelines = {\n",
    "    'RandomForest': (rf_pipeline, rf_param_grid),\n",
    "    'ExtraTrees': (et_pipeline, et_param_grid),\n",
    "    'NeuralNetwork': (nn_pipeline, nn_param_grid)\n",
    "}"
   ],
   "id": "9144427febf622fc",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:48:44.065171Z",
     "start_time": "2025-05-09T22:47:04.470343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dictionary to store best models\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "\n",
    "# Tune each model\n",
    "for model_name, (pipeline, param_grid) in pipelines.items():\n",
    "    print(f\"\\nTuning {model_name}...\")\n",
    "\n",
    "    # Create randomized search\n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=25,  # Number of parameter settings sampled\n",
    "        cv=5,        # 5-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,   # Use all CPU cores\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit randomized search\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Store best model and score\n",
    "    best_models[model_name] = random_search.best_estimator_\n",
    "    best_scores[model_name] = {\n",
    "        'best_params': random_search.best_params_,\n",
    "        'cv_score': random_search.best_score_,\n",
    "        'test_score': random_search.best_estimator_.score(X_test, y_test)\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best parameters for {model_name}:\")\n",
    "    for param, value in random_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"Best CV accuracy: {random_search.best_score_:.4f}\")\n",
    "    print(f\"Test accuracy: {random_search.best_estimator_.score(X_test, y_test):.4f}\")"
   ],
   "id": "9befbadb082f53e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning RandomForest...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best parameters for RandomForest:\n",
      "  classifier__bootstrap: False\n",
      "  classifier__class_weight: None\n",
      "  classifier__max_depth: 20\n",
      "  classifier__max_features: log2\n",
      "  classifier__min_samples_leaf: 1\n",
      "  classifier__min_samples_split: 5\n",
      "  classifier__n_estimators: 661\n",
      "Best CV accuracy: 0.8842\n",
      "Test accuracy: 0.8699\n",
      "\n",
      "Tuning ExtraTrees...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best parameters for ExtraTrees:\n",
      "  classifier__bootstrap: False\n",
      "  classifier__class_weight: None\n",
      "  classifier__max_depth: 20\n",
      "  classifier__max_features: log2\n",
      "  classifier__min_samples_leaf: 1\n",
      "  classifier__min_samples_split: 5\n",
      "  classifier__n_estimators: 661\n",
      "Best CV accuracy: 0.8856\n",
      "Test accuracy: 0.8728\n",
      "\n",
      "Tuning NeuralNetwork...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best parameters for NeuralNetwork:\n",
      "  classifier__activation: tanh\n",
      "  classifier__alpha: 0.010022115592912174\n",
      "  classifier__batch_size: 32\n",
      "  classifier__early_stopping: False\n",
      "  classifier__hidden_layer_sizes: (100,)\n",
      "  classifier__learning_rate_init: 0.053475643163223785\n",
      "  classifier__solver: sgd\n",
      "Best CV accuracy: 0.8893\n",
      "Test accuracy: 0.8931\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:49:32.707560Z",
     "start_time": "2025-05-09T22:49:32.696187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare tuned models\n",
    "print(\"\\nModel Comparison After Tuning:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Model':<15} {'CV Accuracy':<15} {'Test Accuracy':<15}\")\n",
    "print(\"-\" * 60)\n",
    "for model_name in best_scores:\n",
    "    cv_score = best_scores[model_name]['cv_score']\n",
    "    test_score = best_scores[model_name]['test_score']\n",
    "    print(f\"{model_name:<15} {cv_score:.4f}{'':8} {test_score:.4f}{'':8}\")\n",
    "\n",
    "# Identify the best model\n",
    "best_model_name = max(best_scores, key=lambda x: best_scores[x]['test_score'])\n",
    "print(f\"\\nBest model: {best_model_name} with test accuracy {best_scores[best_model_name]['test_score']:.4f}\")"
   ],
   "id": "af7585c4711af22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison After Tuning:\n",
      "------------------------------------------------------------\n",
      "Model           CV Accuracy     Test Accuracy  \n",
      "------------------------------------------------------------\n",
      "RandomForest    0.8842         0.8699        \n",
      "ExtraTrees      0.8856         0.8728        \n",
      "NeuralNetwork   0.8893         0.8931        \n",
      "\n",
      "Best model: NeuralNetwork with test accuracy 0.8931\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:53:04.668704Z",
     "start_time": "2025-05-09T22:52:58.332070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('nn', best_models['NeuralNetwork']),\n",
    "        ('et', best_models['ExtraTrees']),\n",
    "        ('rf', best_models['RandomForest'])\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[0.5, 0.25, 0.25]  # Weight the neural network higher\n",
    ")\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "ensemble_acc = ensemble.score(X_test, y_test)\n",
    "print(f\"Ensemble accuracy: {ensemble_acc:.4f}\")"
   ],
   "id": "629241f8232b1858",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.8960\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:57:20.078728Z",
     "start_time": "2025-05-09T22:57:03.094416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "# Get the best parameters for each model from previous tuning\n",
    "rf_best_params = {k.replace('classifier__', ''): v for k, v in best_scores['RandomForest']['best_params'].items()}\n",
    "et_best_params = {k.replace('classifier__', ''): v for k, v in best_scores['ExtraTrees']['best_params'].items()}\n",
    "nn_best_params = {k.replace('classifier__', ''): v for k, v in best_scores['NeuralNetwork']['best_params'].items()}\n",
    "\n",
    "# Create models with best parameters\n",
    "final_rf = RandomForestClassifier(**rf_best_params, random_state=42)\n",
    "final_et = ExtraTreesClassifier(**et_best_params, random_state=42)\n",
    "final_nn = MLPClassifier(**nn_best_params, random_state=42, max_iter=1000)\n",
    "\n",
    "# Preprocess the complete dataset\n",
    "X_all = ml_data_prepared.drop(columns=['is_win'])\n",
    "y_all = ml_data_prepared['is_win']\n",
    "\n",
    "# Fit preprocessor on all data\n",
    "preprocessor.fit(X_all)\n",
    "\n",
    "# Transform the data\n",
    "X_all_transformed = preprocessor.transform(X_all)\n",
    "\n",
    "# Train each model on the full dataset\n",
    "print(\"Training Random Forest on full dataset...\")\n",
    "final_rf.fit(X_all_transformed, y_all)\n",
    "\n",
    "print(\"Training Extra Trees on full dataset...\")\n",
    "final_et.fit(X_all_transformed, y_all)\n",
    "\n",
    "print(\"Training Neural Network on full dataset...\")\n",
    "final_nn.fit(X_all_transformed, y_all)\n",
    "\n",
    "# Create the final ensemble\n",
    "final_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', final_rf),\n",
    "        ('et', final_et),\n",
    "        ('nn', final_nn)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "print(\"Training Ensemble on full dataset...\")\n",
    "final_ensemble.fit(X_all_transformed, y_all)\n",
    "\n",
    "print(\"All models trained on the full dataset!\")"
   ],
   "id": "e0392c523b09ad2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest on full dataset...\n",
      "Training Extra Trees on full dataset...\n",
      "Training Neural Network on full dataset...\n",
      "Training Ensemble on full dataset...\n",
      "All models trained on the full dataset!\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:57:44.076589Z",
     "start_time": "2025-05-09T22:57:42.910342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a models directory if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, 'models/preprocessor.pkl')\n",
    "\n",
    "# Save individual models\n",
    "joblib.dump(final_rf, 'models/random_forest.pkl')\n",
    "joblib.dump(final_et, 'models/extra_trees.pkl')\n",
    "joblib.dump(final_nn, 'models/neural_network.pkl')\n",
    "\n",
    "# Save the ensemble\n",
    "joblib.dump(final_ensemble, 'models/ensemble.pkl')\n",
    "\n",
    "print(\"All models saved successfully!\")"
   ],
   "id": "5a4a8fea2896970e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models saved successfully!\n"
     ]
    }
   ],
   "execution_count": 105
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
